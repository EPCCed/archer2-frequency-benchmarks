#!/bin/bash

# Slurm job options (name, compute nodes, job time)
#SBATCH --job-name=benchio
#SBATCH --time=00:20:00
#SBATCH --nodes=16
#SBATCH --tasks-per-node=128
#SBATCH --cpus-per-task=1
# Replace [budget code] below with your budget code (e.g. t01)
#SBATCH --account=z19
#SBATCH --partition=standard
#SBATCH --qos=short

cat $0

module swap craype-network-ofi craype-network-ucx
module swap cray-mpich cray-mpich-ucx

module use /work/z19/shared/sfarr/modulefiles
module load adios/2.8.3

module load cray-hdf5-parallel
module load cray-netcdf-hdf5parallel

export OMP_NUM_THREADS=1

ulimit -s unlimited

# Launch the parallel job

export FI_OFI_RXM_SAR_LIMIT=64K
export MPICH_MPIIO_HINTS=*:cray_cb_write_lock_mode=2,*:cray_cb_nodes_multiplier=4

srun --unbuffered --distribution=block:block --hint=nomultithread \
	/work/z19/z19/shared/ARCHER2_CSF/benchio/benchio/benchio 2048 2048 2048 global mpiio fullstriped

srun --unbuffered --distribution=block:block --hint=nomultithread \
        /work/z19/z19/shared/ARCHER2_CSF/benchio/benchio/benchio 2048 2048 2048 global adios unstriped

sleep 120
echo "\n++Energy use:"
sacct -j $SLURM_JOB_ID --format="JobID,NNodes,NTasks,ReqCPUFreq,ElapsedRaw,ConsumedEnergyRaw"

sbatch 2_sub.slurm

Inactive Modules:
  1) cray-mpich


Lmod is automatically replacing "cce/11.0.4" with "gcc/10.2.0".


Lmod is automatically replacing "PrgEnv-cray/8.0.0" with "PrgEnv-gnu/8.0.0".


Lmod is automatically replacing "craype-network-ucx" with "craype-network-ofi".


Inactive Modules:
  1) cray-mpich-ucx


 Simple Parallel IO benchmark
 ----------------------------

 Running on         2048  process(es)

 Running on           16  nodes
 Node number           0  is nid003594 with          128  processes
 Node number           1  is nid003597 with          128  processes
 Node number           2  is nid003599 with          128  processes
 Node number           3  is nid003600 with          128  processes
 Node number           4  is nid003601 with          128  processes
 Node number           5  is nid003602 with          128  processes
 Node number           6  is nid003603 with          128  processes
 Node number           7  is nid003604 with          128  processes
 Node number           8  is nid003612 with          128  processes
 Node number           9  is nid003613 with          128  processes
 Node number          10  is nid003624 with          128  processes
 Node number          11  is nid003626 with          128  processes
 Node number          12  is nid003627 with          128  processes
 Node number          13  is nid003630 with          128  processes
 Node number          14  is nid003631 with          128  processes
 Node number          15  is nid003632 with          128  processes

 Process grid is (           8 ,           16 ,           16 )
 Array size is   (         256 ,          128 ,          128 )
 Global size is  (        2048 ,         2048 ,         2048 )

 Total amount of data =    64.000000000000000       GiB

 Clock resolution is    1.0000000000000000E-003 , usecs

 Using the following IO methods
 ------------------------------
 mpiio                                                           

 Using the following stripings
 -----------------------------
 fullstriped                                                     


 ------
 MPI-IO                                                          
 ------

 Writing to fullstriped/mpiio.dat                                           
 time =    7.5481521841138601      , rate =    8.4788963495856553       GiB/s

 --------
 Finished
 --------


 Simple Parallel IO benchmark
 ----------------------------

 Running on         2048  process(es)

 Running on           16  nodes
 Node number           0  is nid003594 with          128  processes
 Node number           1  is nid003597 with          128  processes
 Node number           2  is nid003599 with          128  processes
 Node number           3  is nid003600 with          128  processes
 Node number           4  is nid003601 with          128  processes
 Node number           5  is nid003602 with          128  processes
 Node number           6  is nid003603 with          128  processes
 Node number           7  is nid003604 with          128  processes
 Node number           8  is nid003612 with          128  processes
 Node number           9  is nid003613 with          128  processes
 Node number          10  is nid003624 with          128  processes
 Node number          11  is nid003626 with          128  processes
 Node number          12  is nid003627 with          128  processes
 Node number          13  is nid003630 with          128  processes
 Node number          14  is nid003631 with          128  processes
 Node number          15  is nid003632 with          128  processes

 Process grid is (           8 ,           16 ,           16 )
 Array size is   (         256 ,          128 ,          128 )
 Global size is  (        2048 ,         2048 ,         2048 )

 Total amount of data =    64.000000000000000       GiB

 Clock resolution is    1.0000000000000000E-003 , usecs

 Using the following IO methods
 ------------------------------
 adios                                                           

 Using the following stripings
 -----------------------------
 unstriped                                                       


 ------
 Adios2                                                          
 ------

 Writing to unstriped/adios.dat                                             
 time =    2.9377584736794233      , rate =    21.785317129846483       GiB/s

 --------
 Finished
 --------

\n++Energy use:
JobID          NNodes   NTasks ReqCPUFreq ElapsedRaw ConsumedEnergyRaw 
------------ -------- -------- ---------- ---------- ----------------- 
3064585            16             Unknown        159                   
3064585.bat+        1        1          0        159                 0 
3064585.ext+       16       16          0        159                 0 
3064585.0          16     2048         2G         20             80492 
3064585.1          16     2048         2G         13             49972 
Submitted batch job 3064596
