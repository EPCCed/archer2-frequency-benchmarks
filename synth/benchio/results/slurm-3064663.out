#!/bin/bash

# Slurm job options (name, compute nodes, job time)
#SBATCH --job-name=benchio
#SBATCH --time=00:20:00
#SBATCH --nodes=16
#SBATCH --tasks-per-node=128
#SBATCH --cpus-per-task=1
# Replace [budget code] below with your budget code (e.g. t01)
#SBATCH --account=z19
#SBATCH --partition=standard
#SBATCH --qos=short

cat $0

module swap craype-network-ofi craype-network-ucx
module swap cray-mpich cray-mpich-ucx

module use /work/z19/shared/sfarr/modulefiles
module load adios/2.8.3

module load cray-hdf5-parallel
module load cray-netcdf-hdf5parallel

export OMP_NUM_THREADS=1

ulimit -s unlimited

# Launch the parallel job

export FI_OFI_RXM_SAR_LIMIT=64K
export MPICH_MPIIO_HINTS=*:cray_cb_write_lock_mode=2,*:cray_cb_nodes_multiplier=4

srun --unbuffered --distribution=block:block --hint=nomultithread \
	/work/z19/z19/shared/ARCHER2_CSF/benchio/benchio/benchio 2048 2048 2048 global mpiio fullstriped

srun --unbuffered --distribution=block:block --hint=nomultithread \
        /work/z19/z19/shared/ARCHER2_CSF/benchio/benchio/benchio 2048 2048 2048 global adios unstriped

sleep 120
echo "\n++Energy use:"
sacct -j $SLURM_JOB_ID --format="JobID,NNodes,NTasks,ReqCPUFreq,ElapsedRaw,ConsumedEnergyRaw"


Inactive Modules:
  1) cray-mpich


Lmod is automatically replacing "cce/11.0.4" with "gcc/10.2.0".


Lmod is automatically replacing "PrgEnv-cray/8.0.0" with "PrgEnv-gnu/8.0.0".


Lmod is automatically replacing "craype-network-ucx" with "craype-network-ofi".


Inactive Modules:
  1) cray-mpich-ucx


 Simple Parallel IO benchmark
 ----------------------------

 Running on         2048  process(es)

 Running on           16  nodes
 Node number           0  is nid003594 with          128  processes
 Node number           1  is nid003597 with          128  processes
 Node number           2  is nid003599 with          128  processes
 Node number           3  is nid003600 with          128  processes
 Node number           4  is nid003601 with          128  processes
 Node number           5  is nid003602 with          128  processes
 Node number           6  is nid003603 with          128  processes
 Node number           7  is nid003604 with          128  processes
 Node number           8  is nid003612 with          128  processes
 Node number           9  is nid003613 with          128  processes
 Node number          10  is nid003624 with          128  processes
 Node number          11  is nid003626 with          128  processes
 Node number          12  is nid003627 with          128  processes
 Node number          13  is nid003630 with          128  processes
 Node number          14  is nid003631 with          128  processes
 Node number          15  is nid003632 with          128  processes

 Process grid is (           8 ,           16 ,           16 )
 Array size is   (         256 ,          128 ,          128 )
 Global size is  (        2048 ,         2048 ,         2048 )

 Total amount of data =    64.000000000000000       GiB

 Clock resolution is    1.0000000000000000E-003 , usecs

 Using the following IO methods
 ------------------------------
 mpiio                                                           

 Using the following stripings
 -----------------------------
 fullstriped                                                     


 ------
 MPI-IO                                                          
 ------

 Writing to fullstriped/mpiio.dat                                           
 time =    7.4349251911044121      , rate =    8.6080220520003916       GiB/s

 --------
 Finished
 --------


 Simple Parallel IO benchmark
 ----------------------------

 Running on         2048  process(es)

 Running on           16  nodes
 Node number           0  is nid003594 with          128  processes
 Node number           1  is nid003597 with          128  processes
 Node number           2  is nid003599 with          128  processes
 Node number           3  is nid003600 with          128  processes
 Node number           4  is nid003601 with          128  processes
 Node number           5  is nid003602 with          128  processes
 Node number           6  is nid003603 with          128  processes
 Node number           7  is nid003604 with          128  processes
 Node number           8  is nid003612 with          128  processes
 Node number           9  is nid003613 with          128  processes
 Node number          10  is nid003624 with          128  processes
 Node number          11  is nid003626 with          128  processes
 Node number          12  is nid003627 with          128  processes
 Node number          13  is nid003630 with          128  processes
 Node number          14  is nid003631 with          128  processes
 Node number          15  is nid003632 with          128  processes

 Process grid is (           8 ,           16 ,           16 )
 Array size is   (         256 ,          128 ,          128 )
 Global size is  (        2048 ,         2048 ,         2048 )

 Total amount of data =    64.000000000000000       GiB

 Clock resolution is    1.0000000000000000E-003 , usecs

 Using the following IO methods
 ------------------------------
 adios                                                           

 Using the following stripings
 -----------------------------
 unstriped                                                       


 ------
 Adios2                                                          
 ------

 Writing to unstriped/adios.dat                                             
 time =    4.3656022436916828      , rate =    14.660062100820184       GiB/s

 --------
 Finished
 --------

\n++Energy use:
JobID          NNodes   NTasks ReqCPUFreq ElapsedRaw ConsumedEnergyRaw 
------------ -------- -------- ---------- ---------- ----------------- 
3064663            16             Unknown        162                   
3064663.bat+        1        1          0        162                 0 
3064663.ext+       16       16          0        162                 0 
3064663.0          16     2048         2G         21             90840 
3064663.1          16     2048         2G         10             45794 
